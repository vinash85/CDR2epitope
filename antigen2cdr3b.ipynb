{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todos \n",
    "1. Correct CDR3 kmerization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import r2python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: 'NULL', 1: 'SOS', 2: 'EOS'}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words +=1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines ...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' %(lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence) \n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# ## check if the view is accurate \n",
    "# def tensorFromSentences(lang, sentences):\n",
    "#     indexes_mat = [indexesFromSentence(lang, sentence) for sentence in sentences]\n",
    "#     return torch.tensor(indexes_mat, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor_mat = tensorFromSentences(output_lang, pair[1])\n",
    "    prior_z_np = np.ones(length(target_tensor_mat))/length(target_tensor_mat)\n",
    "    prior_z =  torch.tensor(prior_z_np, dtype=torch.long, device=device)\n",
    "    return (input_tensor, target_tensor, prior_z)\n",
    "# len(pairs[0])\n",
    "# random.choice(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInput_cdr3b(lang, langfile):\n",
    "    print(\"Reading %s ...\" %(lang))\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    df = pd.read_csv(langfile, \"\\t\")\n",
    "\n",
    "    df = df[['kmer.sentence', 'patient']]\n",
    "    input_lang = Lang(lang)\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for kmerS in df['kmer.sentence']:\n",
    "        input_lang.addSentence(kmerS)\n",
    "        \n",
    "    df['kmer.tensor'] = df['kmer.sentence'].apply(lambda x: tensorFromSentence(input_lang, x))\n",
    "    \n",
    "    return input_lang, df\n",
    "\n",
    "def readInput_epitope(lang, langfile, nfold=None):\n",
    "    \"\"\"The module reads CDR3 and Epitopes of and create lists for each tcga patients\n",
    "    output are\n",
    "    cdr3s_list: list of cdr3 per common patient,\n",
    "    neoantigens_list: list of Epitope per common patient,\n",
    "    negative_patients: For each patient list of other patients that does not share any neoantigen with the patient\n",
    "\n",
    "    approx schematic of the function\n",
    "\n",
    "\n",
    "    # read files\n",
    "    # find common paitents\n",
    "    # convert to tensor\n",
    "    # create list\n",
    "    \"\"\"\n",
    "    def create_neoantigen_list_from_patient_list(patients_lists, nfold=None):\n",
    "        \"\"\"\n",
    "        Ouput neoantigen for patients list\n",
    "        \"\"\"\n",
    "        \n",
    "        df_common = df[df['patient'].isin(patients_lists)]\n",
    "        neoantigens_list = []\n",
    "        for patient_inx, patient in zip(range(len(patients_lists)), patients_lists):\n",
    "            neoantigen_curr = df_common[df_common['patient'] == patient]['kmer.tensor']\n",
    "            neoantigens_list.append(neoantigen_curr)\n",
    "\n",
    "        neoantigens_list = [neoantigen.values.tolist() for neoantigen in neoantigens_list]\n",
    "        return neoantigens_list\n",
    "    \n",
    "    df = pd.read_csv(langfile, \"\\t\")\n",
    "    \n",
    "    input_lang = Lang(lang)\n",
    "    print(\"Counting words...\")\n",
    "    for kmerS in df['kmer.sentence']:\n",
    "        input_lang.addSentence(kmerS)\n",
    "        \n",
    "    df['kmer.tensor'] = df['kmer.sentence'].apply(lambda x: tensorFromSentence(input_lang, x))\n",
    "    common_patients = r2python.unique(df['patient'])\n",
    "    if nfold is None:\n",
    "        train_patients_list = common_patients\n",
    "        trainData = create_neoantigen_list_from_patient_list(train_patients_list)\n",
    "        testData = None\n",
    "    else:\n",
    "        ### this is not working\n",
    "        train_patients_list = r2python.sample(common_patients, size=int((nfold - 1) * len(common_patients) / nfold))\n",
    "        test_patients_list = r2python.setdiff(common_patients, train_patients_list)\n",
    "        trainData = create_neoantigen_list_from_patient_list(train_patients_list)\n",
    "        testData = create_neoantigen_list_from_patient_list(test_patients_list)\n",
    "\n",
    "    dataset = {\n",
    "        \"trainData\": trainData,\n",
    "        \"testData\": testData\n",
    "    }\n",
    "    return input_lang, dataset, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cdr3b ...\n",
      "Counting words...\n",
      "Read 999 cdr3bs \n",
      "Counting words...\n",
      "Read 2 epitope \n",
      "Counted words:\n",
      "cdr3b 3062\n",
      "eptiope 5168\n"
     ]
    }
   ],
   "source": [
    "# def format2tensorList(List):\n",
    "#     # assumes that indices are in sorted order\n",
    "#     tensorList = []\n",
    "#     total_indices = int(List[len(List)-1][1])\n",
    "#     initial_index = 1\n",
    "#     for inx in range(total_indices):\n",
    "#         tensorList_set = []\n",
    "#         curr\n",
    "        \n",
    "def prepareData(cdr3b, cdr3bfile, epitope, epitopefile):\n",
    "    cdr3b_lang,  df_cdr3 = readInput_cdr3b(cdr3b, cdr3bfile)\n",
    "    print(\"Read %s cdr3bs \" % len(df_cdr3.index))\n",
    "\n",
    "\n",
    "    epitope_lang,  epitope_patient_list, df_epitope = readInput_epitope(epitope, epitopefile)\n",
    "    print(\"Read %s epitope \" % len(epitope_patient_list))\n",
    "    \n",
    "    \n",
    "    # epitope NULL sentence\n",
    "    epitope_lang.addSentence('NULL')\n",
    "    epitopee_null = tensorFromSentence(epitope_lang, 'NULL')\n",
    "\n",
    "    \n",
    "        \n",
    "#     for pair in epitope_n_index:\n",
    "#         epitope_lang.addSentence(pair[0])  \n",
    "        \n",
    "#     epitope_matList = format2ListofList(epitope_lang, epitope_n_index)\n",
    "#         epitope_mat_lens.addLens(pair[1])\n",
    "    \n",
    "#     convert epitope to list of matrices for fast indexing \n",
    "  \n",
    "    print(\"Counted words:\")\n",
    "    print(cdr3b_lang.name, cdr3b_lang.n_words)\n",
    "    print(epitope_lang.name, epitope_lang.n_words)\n",
    "    return cdr3b_lang, epitope_lang, df_cdr3, epitope_patient_list, epitopee_null, df_epitope\n",
    "\n",
    "cdr3b_lang, epitope_lang, df_cdr3, epitope_patient_list, epitope_null, df_epitope = prepareData('cdr3b', 'data/tcga_epitope_V2.2000.txt','eptiope', 'data/all.9mers_200.txt')\n",
    "# print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([random.choice(pairs) for i in range(10)])\n",
    "# pairs[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,  hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,  hidden_size, output_size, dropout_p =0.1, max_length = MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "#         attn_weights = self.attn(torch.cat((embedded[0], hidden[0]), 1))\n",
    "#         attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output= F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "In this model, we are generating Epitope (X) from the CDR3b (Y). This weird convention is for traditional reason. \n",
    "So the input is CDR3B and output are Antigens. \n",
    "\n",
    "\\begin{align}\n",
    "log P(X/Y) &= \\sum_{x} log P(x/Y) \\\\ \n",
    "            &= \\sum_{x} log \\sum_z P(x,z/Y) \\\\ \n",
    "            &= \\sum_{x} log \\sum_z P(z/Y) P(x/z,Y) \\\\\n",
    "            &= \\sum_{x} log \\mathbf{E}_z  P(x/z,Y) \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### TODO : Add prior proportial to expression, mhc1 presentation, clonality of mutation \n",
    "### TODO : Add prior proportial to its clonality of CDR3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train_set(input_tensor_list, target_tensor, input_null, prior_z, encoder, decoder, encoder_optimizer,\n",
    "              decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    ''' The function inputs cdr3bs and antigens of a set (patient) and for probability of each cdr3b generated by\n",
    "    each antigens. And  also calculate the loss'''\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "#     print(len(input_tensor_list))\n",
    "\n",
    "    inputs_num = len(input_tensor_list)\n",
    "    for input_inx in range(inputs_num + 1):\n",
    "#         print(len(input_tensor_list))\n",
    "#         print(\"inx:\")\n",
    "#         print(input_inx)\n",
    "        if input_inx > 0:\n",
    "            prior_z_curr = prior_z[1]\n",
    "            input_tensor = input_tensor_list[input_inx-1]\n",
    "        else:\n",
    "            prior_z_curr = prior_z[0]\n",
    "            input_tensor = input_null\n",
    "\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "    #     print(target_length)\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size,\n",
    "                                      device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                loss += prior_z_curr * criterion(decoder_output, target_tensor[di])\n",
    "                decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                loss += prior_z_curr * criterion(decoder_output, target_tensor[di])\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, total_patients, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_inx = r2python.sample_int(total_patients, size=n_iters, replace=True)\n",
    "#     training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "#                       for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        inx_curr = training_inx[iter -1]\n",
    "        input_tensor_list = epitope_patient_list['trainData'][inx_curr]\n",
    "#         print(len(input_tensor_list))\n",
    "#         print(input_tensor_list[0])\n",
    "        target_tensor = df_cdr3['kmer.tensor'][inx_curr]\n",
    "        prior_z = [0.5, 0.5/len(input_tensor_list)]  # prior of NULL distribution, uniform prior \n",
    "\n",
    "        loss = train_set(input_tensor_list, target_tensor, epitope_null, prior_z, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "#         print(sentence)\n",
    "        input_tensor = tensorFromSentence(cdr3b_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(epitope_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, total_patients = 3, n=10, ):\n",
    "    for i in range(n):\n",
    "#         pair = random.choice(pairs)\n",
    "        \n",
    "        training_inx = r2python.sample_int(total_patients, size=1, replace=True)\n",
    "#         print(training_inx)\n",
    "#         print(type(training_inx))\n",
    "\n",
    "        inx_curr = training_inx[0]\n",
    "        epitope_curr = df_epitope['kmer.sentence'][inx_curr]\n",
    "        cdr3b_curr = df_cdr3['kmer.sentence'][inx_curr]\n",
    "        \n",
    "        print('>', cdr3b_curr)\n",
    "        print('=', epitope_curr)\n",
    "        output_words, attentions = evaluate(encoder, decoder, cdr3b_curr)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 54s (- 2m 42s) (1 25%) 8.0369\n",
      "1m 24s (- 1m 24s) (2 50%) 2.7497\n",
      "1m 59s (- 0m 39s) (3 75%) 2.1054\n",
      "2m 12s (- 0m 0s) (4 100%) 6.1637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(epitope_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, cdr3b_lang.n_words, dropout_p=0.1).to(device)\n",
    "total_patients = 3\n",
    "trainIters(encoder1, attn_decoder1, n_iters=4, total_patients=total_patients, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ^^^^C ^^^CS ^^CSA ^CSAE CSAEQ SAEQG AEQGA EQGAV QGAVT GAVTG AVTGE VTGEL TGELF\n",
      "= ^^^^Y ^^^YS ^^YST ^YSTK YSTKH STKHS TKHSK KHSKL HSKLY SKLY$ KLY$$ LY$$$ Y$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASSL ASSLF SSLFP SLFPL LFPLA FPLAD PLADE LADEQ ADEQF\n",
      "= ^^^^S ^^^ST ^^STK ^STKH STKHS TKHSK KHSKL HSKLY SKLYI KLYI$ LYI$$ YI$$$ I$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASST ASSTD SSTDR STDRA TDRAY DRAYE RAYEQ AYEQY YEQYF\n",
      "= ^^^^L ^^^LY ^^LYS ^LYST LYSTK YSTKH STKHS TKHSK KHSKL HSKL$ SKL$$ KL$$$ L$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASST ASSTD SSTDR STDRA TDRAY DRAYE RAYEQ AYEQY YEQYF\n",
      "= ^^^^L ^^^LY ^^LYS ^LYST LYSTK YSTKH STKHS TKHSK KHSKL HSKL$ SKL$$ KL$$$ L$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASST ASSTD SSTDR STDRA TDRAY DRAYE RAYEQ AYEQY YEQYF\n",
      "= ^^^^L ^^^LY ^^LYS ^LYST LYSTK YSTKH STKHS TKHSK KHSKL HSKL$ SKL$$ KL$$$ L$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASSL ASSLF SSLFP SLFPL LFPLA FPLAD PLADE LADEQ ADEQF\n",
      "= ^^^^S ^^^ST ^^STK ^STKH STKHS TKHSK KHSKL HSKLY SKLYI KLYI$ LYI$$ YI$$$ I$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASST ASSTD SSTDR STDRA TDRAY DRAYE RAYEQ AYEQY YEQYF\n",
      "= ^^^^L ^^^LY ^^LYS ^LYST LYSTK YSTKH STKHS TKHSK KHSKL HSKL$ SKL$$ KL$$$ L$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASST ASSTD SSTDR STDRA TDRAY DRAYE RAYEQ AYEQY YEQYF\n",
      "= ^^^^L ^^^LY ^^LYS ^LYST LYSTK YSTKH STKHS TKHSK KHSKL HSKL$ SKL$$ KL$$$ L$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CS ^^CSA ^CSAE CSAEQ SAEQG AEQGA EQGAV QGAVT GAVTG AVTGE VTGEL TGELF\n",
      "= ^^^^Y ^^^YS ^^YST ^YSTK YSTKH STKHS TKHSK KHSKL HSKLY SKLY$ KLY$$ LY$$$ Y$$$$\n",
      "< <EOS>\n",
      "\n",
      "> ^^^^C ^^^CA ^^CAS ^CASS CASSL ASSLF SSLFP SLFPL LFPLA FPLAD PLADE LADEQ ADEQF\n",
      "= ^^^^S ^^^ST ^^STK ^STKH STKHS TKHSK KHSKL HSKLY SKLYI KLYI$ LYI$$ YI$$$ I$$$$\n",
      "< <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10dd9acc0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"^^^^C ^^^CA ^^CAS ^CASS CASSL ASSLF SSLFP SLFPL LFPLA FPLAD PLADE LADEQ ADEQF\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = ^^^^C ^^^CS ^^CSA ^CSAE CSAEQ SAEQG AEQGA EQGAV QGAVT GAVTG AVTGE VTGEL TGELF\n",
      "output = <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"^^^^C ^^^CS ^^CSA ^CSAE CSAEQ SAEQG AEQGA EQGAV QGAVT GAVTG AVTGE VTGEL TGELF\")\n",
    "\n",
    "# evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "# evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "# evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a kmer from CDR3 and antigen, with stride =1. The line will end with \".\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
