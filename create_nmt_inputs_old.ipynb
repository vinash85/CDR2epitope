{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs CDR3-Epitope for language translation\n",
    "==========================================\n",
    "\n",
    "The program needs 3 lang1 and lang2 files\n",
    "1. train \n",
    "2. dev (most likely validation set for setting hyperparams?)\n",
    "3. test\n",
    "\n",
    "The above files are subscript with language subsscript (e.g. \"en\" and \"vi\") have one sentence per line. The lines are paired (at least) in the training set. \n",
    "\n",
    "_train.en_\n",
    "\"That report was written by 620 scientists from 40 countries .\"\n",
    "_train.vi_\n",
    "\"Nghiên cứu được viết bởi 620 nhà khoa học từ 40 quốc gia khác nhau .\"\n",
    "\n",
    "In addition it also needs vocabulory for lang1 and lang2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "import tensorflow as tf\n",
    "import r2python\n",
    "import numpy as np\n",
    "import platform\n",
    "import pandas as pd\n",
    "if platform.system() != 'Darwin':\n",
    "    import matplotlib as mpl\n",
    "    mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from time import strftime\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import  csv\n",
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a kmer from CDR3 and antigen, with stride =1. The line will end with \".\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_antigen_cdr3b_kmers(\n",
    "    train_set_filename,\n",
    "    outputDir=\".\",\n",
    "    prefix=\"train\",\n",
    "    kmer_len=3,\n",
    "    vocab_CDR3b = [],\n",
    "    vocab_epitope = [],\n",
    "    min_CDR3b_len=None,\n",
    "    max_CDR3b_len=None,\n",
    "    # min_CDR3a_len=7,\n",
    "    # max_CDR3a_len=17,\n",
    "    min_epitope_len=None,\n",
    "    max_epitope_len=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a kmers for antigen and cdr3b. \n",
    "    \"\"\"\n",
    "    df_nu = pd.read_csv(train_set_filename, \"\\t\")\n",
    "    duplicate_index = df_nu['CDR3b'].duplicated(keep='first')\n",
    "    df = df_nu[~duplicate_index]\n",
    "    df_select = df\n",
    "    if min_CDR3b_len is not None:\n",
    "        df_select = df[df['CDR3b'].str.len() >= min_CDR3b_len]\n",
    "    if max_CDR3b_len is not None:\n",
    "        df_select = df_select[df_select['CDR3b'].str.len() <= max_CDR3b_len]\n",
    "    if min_epitope_len is not None:\n",
    "        df_select = df[df['Epitope'].str.len() >= min_epitope_len]\n",
    "    if max_epitope_len is not None:\n",
    "        df_select = df_select[df_select['Epitope'].str.len() <= max_epitope_len]\n",
    "    print(\"Dataset size:\")\n",
    "    print(df_select.shape)\n",
    "    df_unique = df_select\n",
    "    cdr3s_list = df_unique['CDR3b'].tolist()\n",
    "    cdr3s_kmers_precontext, cdr3s_kmers, cdr3s_kmers_postcontext = [], [], []\n",
    "    for inx in range(len(cdr3s_list)):\n",
    "        cdr3 = cdr3s_list[inx]\n",
    "        cdr3_kmers = [cdr3[cdr3_inx:(cdr3_inx + kmer_len)] for cdr3_inx in range(0, len(cdr3) - (kmer_len - 1))]\n",
    "        cdr3_kmers = cdr3_kmers + [\".\"]\n",
    "        cdr3s_kmers.append(cdr3_kmers)\n",
    "    \n",
    "#     import ipdb; ipdb.set_trace()\n",
    "\n",
    "    filename = (f'{outputDir}/{prefix}.cdr3b')\n",
    "    with open(filename,\"w\") as f:\n",
    "        wr = csv.writer(f, lineterminator='\\n', delimiter=' ')\n",
    "        wr.writerows(cdr3s_kmers)\n",
    "        \n",
    "    epitopes_list = df_unique['Epitope'].tolist()\n",
    "    epitopes_kmers_precontext, epitopes_kmers, epitopes_kmers_postcontext = [], [], []\n",
    "    for inx in range(len(epitopes_list)):\n",
    "        epitope = epitopes_list[inx]\n",
    "        epitope_kmers = [epitope[epitope_inx:(epitope_inx + kmer_len)] for epitope_inx in range(0, len(epitope) - (kmer_len - 1))]\n",
    "        epitope_kmers = epitope_kmers + [\".\"]\n",
    "        epitopes_kmers.append(epitope_kmers)\n",
    "\n",
    "    filename = (f'{outputDir}/{prefix}.epitope')\n",
    "#     print(filename)\n",
    "    with open(filename,\"w\") as f:\n",
    "        wr = csv.writer(f, lineterminator='\\n', delimiter=' ')\n",
    "        wr.writerows(epitopes_kmers)\n",
    "        \n",
    "#     filename = (f'{outputDir}/{prefix}.cdr3b')\n",
    "    # create vocabulary \n",
    "    vocab_CDR3b = list(set([item for sublist in cdr3s_kmers for item in sublist] + vocab_CDR3b))\n",
    "    vocab_CDR3b_all = [\"<unk>\", \"<s>\", \"</s>\"] + vocab_CDR3b\n",
    "    filename = (f'{outputDir}/{prefix}_vocab.cdr3b')\n",
    "    with open(filename,\"w\") as f:\n",
    "        wr = csv.writer(f, lineterminator='\\n', delimiter=' ')\n",
    "        for elem in vocab_CDR3b_all:\n",
    "            wr.writerow([elem])\n",
    "        \n",
    "#         wr.writerows(vocab_CDR3b_all)\n",
    "\n",
    "    vocab_epitope = list(set([item for sublist in epitopes_kmers for item in sublist] + vocab_epitope))\n",
    "    vocab_epitope_all = [\"<unk>\", \"<s>\", \"</s>\"] + vocab_epitope \n",
    "    filename = (f'{outputDir}/{prefix}_vocab.epitopes')\n",
    "    with open(filename,\"w\") as f:\n",
    "        wr = csv.writer(f, lineterminator='\\n', delimiter=' ')\n",
    "        for elem in vocab_epitope_all:\n",
    "            wr.writerow([elem])\n",
    "        \n",
    "#         wr.writerows(vocab_epitope)\n",
    "        \n",
    "    return cdr3s_kmers, epitopes_kmers, vocab_CDR3b, vocab_epitope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:\n",
      "(23555, 2)\n",
      "Dataset size:\n",
      "(5857, 3)\n"
     ]
    }
   ],
   "source": [
    "outputDir=\"/Users/avi/project/code/deeplearning/antigen_recognition/data/nmt_inps_2mer\"\n",
    "\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "_, _, vocab_train_cdr3b, vocab_train_epitope = create_antigen_cdr3b_kmers(\n",
    "    train_set_filename=\"/Users/avi/project/code/deeplearning/antigen_recognition/data/vdjdb_B.tsv\",\n",
    "    outputDir=outputDir,\n",
    "    kmer_len = 2)\n",
    "\n",
    "out_test = create_antigen_cdr3b_kmers(\n",
    "    train_set_filename=\"/Users/avi/project/code/deeplearning/antigen_recognition/data/CDR3a_CDR3b_Epitope.tsv\",\n",
    "    outputDir=outputDir, prefix=\"test\",\n",
    "    kmer_len = 2, vocab_CDR3b = vocab_train_cdr3b, vocab_epitope = vocab_train_epitope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$outputDir\"\n",
    "head -3000 $1/test.epitope > $1/test_3000.epitope\n",
    "tail -n +3000 $1/test.epitope > $1/test_end.epitope\n",
    "\n",
    "head -3000 $1/test.cdr3b > $1/test_3000.cdr3b\n",
    "tail -n +3000 $1/test.cdr3b > $1/test_end.cdr3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(out_train))\n",
    "# print(len(vocab_train_cdr3b))\n",
    "# print(len(out_test[3]))\n",
    "aa = list([1,2,3, 4,4,4,5] + [])\n",
    "set(aa)\n",
    "\n",
    "with open(\"temp.txt\",\"w\") as f:\n",
    "    wr = csv.writer(f, lineterminator='\\n', delimiter=' ')\n",
    "    for elem in aa:\n",
    "        wr.writerow([elem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos: \n",
    "\n",
    "+ Remove C and A. So that the training and testing set are good. \n",
    "+ create 2mer mode\n",
    "+ Make inference with current model\n",
    "+ Change the loss function\n",
    "+ Try attention model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
